{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kg/.virtualenvs/deeplearning/lib/python2.7/site-packages/ipykernel_launcher.py:166: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2918\n",
      "830\n",
      "0.284441398218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import applications, backend as K, optimizers\n",
    "\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 52, 52\n",
    "\n",
    "first_try_model_path = 'first_try.h5'\n",
    "fine_tuned_model_weights_path = 'finetuned_model.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_samples_no = 2917\n",
    "nb_samples_yes = 2443\n",
    "nb_train_samples = nb_samples_no + nb_samples_yes\n",
    "nb_validation_samples = nb_samples_no + nb_samples_yes\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "def create_model():\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # this is the augmentation configuration we will use for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    # this is the augmentation configuration we will use for testing:\n",
    "    # only rescaling\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "    model.save_weights(first_try_model_path)\n",
    "\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'w'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'w'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "    train_labels = np.array(\n",
    "        [0] * nb_samples_no + [1] * nb_samples_yes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * nb_samples_no + [1] * nb_samples_yes)\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "def create_top_model():\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=(img_height, img_width, 3))\n",
    "    print('Model loaded.')\n",
    "\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # note that it is necessary to start with a fully-trained\n",
    "    # classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    model = Model(input=model.input, output=top_model(model.output))\n",
    "\n",
    "    return model\n",
    "\n",
    "def fine_tune():\n",
    "    model = create_top_model()\n",
    "    # set the first 15 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    # fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "    \n",
    "    model.save_weights(fine_tuned_model_weights_path)\n",
    "\n",
    "### START\n",
    "# from https://github.com/philipperemy/keras-visualize-activations/blob/master/read_activations.py\n",
    "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        # only one input! let's wrap it in a list.\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    # Learning phase. 0 = Test mode (no dropout or batch normalization)\n",
    "    # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]\n",
    "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def display_activations(activation_maps):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \"\"\"\n",
    "    (1, 26, 26, 32)\n",
    "    (1, 24, 24, 64)\n",
    "    (1, 12, 12, 64)\n",
    "    (1, 12, 12, 64)\n",
    "    (1, 9216)\n",
    "    (1, 128)\n",
    "    (1, 128)\n",
    "    (1, 10)\n",
    "    \"\"\"\n",
    "    batch_size = activation_maps[0].shape[0]\n",
    "    assert batch_size == 1, 'One image at a time to visualize.'\n",
    "    for i, activation_map in enumerate(activation_maps):\n",
    "        print('Displaying activation map {}'.format(i))\n",
    "        shape = activation_map.shape\n",
    "        if len(shape) == 4:\n",
    "            activations = np.hstack(np.transpose(activation_map[0], (2, 0, 1)))\n",
    "        elif len(shape) == 2:\n",
    "            # try to make it square as much as possible. we can skip some activations.\n",
    "            activations = activation_map[0]\n",
    "            num_activations = len(activations)\n",
    "            if num_activations > 1024:  # too hard to display it on the screen.\n",
    "                square_param = int(np.floor(np.sqrt(num_activations)))\n",
    "                activations = activations[0: square_param * square_param]\n",
    "                activations = np.reshape(activations, (square_param, square_param))\n",
    "            else:\n",
    "                activations = np.expand_dims(activations, axis=0)\n",
    "        else:\n",
    "            raise Exception('len(shape) = 3 has not been implemented.')\n",
    "        plt.imshow(activations, interpolation='None', cmap='jet')\n",
    "        plt.show()\n",
    "### END\n",
    "\n",
    "def plot_trained_model(weights_path):\n",
    "    model = create_model()\n",
    "    model.load_weights(weights_path)\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    activations = get_activations(model, validation_generator[0][0][0:1], print_shape_only=True)\n",
    "    display_activations(activations)\n",
    "\n",
    "    if False:\n",
    "        plot_model(model, to_file=weights_path + '.png', show_shapes=True)\n",
    "\n",
    "def predict(weights_path):\n",
    "    model = create_top_model()\n",
    "    model.load_weights(fine_tuned_model_weights_path)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in xrange(0, 2963):\n",
    "        try:\n",
    "            img = image.load_img('%s/no/%i.png' % (validation_data_dir, i))\n",
    "        except IOError:\n",
    "            continue\n",
    "\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        y = model.predict(x).tolist()[0][0]\n",
    "        results.append(1 if y > 0.5 else 0)        \n",
    "\n",
    "    print(len(results))\n",
    "    print(sum(results))\n",
    "    print((sum(results) * 1.0) / len(results))\n",
    "\n",
    "\n",
    "def run(part_i=False,\n",
    "        part_ii=False, \n",
    "        part_iii=False, \n",
    "        analytics=False, \n",
    "        predictions=False):\n",
    "    ### Part I\n",
    "    if part_i:\n",
    "        build_model()\n",
    "\n",
    "    ### Part II\n",
    "    if part_ii:    \n",
    "        save_bottleneck_features()\n",
    "        train_top_model()\n",
    "\n",
    "    ### Part III\n",
    "    if part_iii:\n",
    "        fine_tune()\n",
    "\n",
    "    ### Analysis\n",
    "    if analytics:\n",
    "        plot_trained_model(first_try_model_path)\n",
    "\n",
    "    ### Prediction\n",
    "    if predictions:\n",
    "        predict(fine_tuned_model_weights_path)\n",
    "        \n",
    "run(predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
